{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from ray import tune\n",
    "\n",
    "from fllib.datasets import DatasetCatalog\n",
    "\n",
    "sns.set(font='Times New Roman', font_scale=1)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\", rc={\"lines.linewidth\": 4})\n",
    "font_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c30e65a99c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(dataset_config):\n",
    "    dataset = DatasetCatalog.get_dataset(dataset_config)\n",
    "\n",
    "    data = {}\n",
    "    for i, client_dataset in enumerate(dataset.client_datasets):\n",
    "        # Assuming client_dataset.train_set.dataset.targets is accessible\n",
    "        # and contains all targets\n",
    "        all_targets = torch.tensor(client_dataset.train_set.dataset.targets)\n",
    "\n",
    "        # Now, use the indices from the Subset to filter out the relevant targets\n",
    "        subset_indices = torch.tensor(client_dataset.train_set.indices)\n",
    "        targets = all_targets[subset_indices]\n",
    "\n",
    "        # Count the occurrences of each unique target\n",
    "        unique, counts = torch.unique(targets, return_counts=True)\n",
    "\n",
    "        # Convert to a dictionary or another suitable format if necessary\n",
    "        class_counts = dict(zip(unique.tolist(), counts.tolist()))\n",
    "        data[f\"Client {i}\"] = class_counts\n",
    "        classes = range(10)  # Assuming 10 classes\n",
    "    x, y, sizes = [], [], []\n",
    "    \n",
    "    for client, counts in data.items():\n",
    "        client_id = int(client.split()[1])\n",
    "        for class_id in classes:\n",
    "            x.append(client_id)\n",
    "            y.append(class_id)\n",
    "            sizes.append(counts.get(class_id, 0))\n",
    "    return {\"config\": dataset_config, \"result\": (x, y, sizes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88620f62d77b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.1, 1.0, 10.0][::-1]\n",
    "dataset_config = {\n",
    "    \"type\": \"CIFAR10\",\n",
    "    \"splitter_config\": {\n",
    "        \"type\": \"DirichletSplitter\",\n",
    "        \"random_seed\": 12345,\n",
    "        \"num_clients\": 15,\n",
    "        \"alpha\": tune.grid_search(alphas)\n",
    "    },\n",
    "}\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    partition_dataset,\n",
    "    param_space=dataset_config,\n",
    ")\n",
    "results = tuner.fit()\n",
    "\n",
    "dfs = []\n",
    "for result in results:\n",
    "    params_path = os.path.join(result.path, \"params.pkl\")\n",
    "    result_path = os.path.join(result.path, \"result.json\")\n",
    "    # 读取 .pkl 文件\n",
    "    with open(params_path, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    \n",
    "    with open(result_path, 'r') as file:\n",
    "        exp_result = json.load(file)\n",
    "\n",
    "    # 创建 DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'x': exp_result['result'][0],\n",
    "        'y': exp_result['result'][1],\n",
    "        'sizes': exp_result['result'][2],\n",
    "        'alpha': [params['splitter_config']['alpha']]* len(exp_result['result'][0])\n",
    "    })\n",
    "    dfs.append(df)\n",
    "df_combined = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00fbcb77a38c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建 FacetGrid 对象\n",
    "g = sns.FacetGrid(df_combined, col=\"alpha\", col_wrap=4, col_order=alphas, height=4., sharey=True, sharex=False)\n",
    "\n",
    "# 在每个子网格中添加散点图\n",
    "g.map_dataframe(sns.scatterplot, 'x', 'y', size='sizes', hue='x', sizes=(0, 500), palette=\"muted\",\n",
    "    edgecolor=\"black\", linewidth=1, \n",
    "    legend=False,)\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for _, spine in ax.spines.items():\n",
    "        spine.set_visible(True)\n",
    "    new_title = r\"$\\alpha$ = \" + ax.get_title().split(\"=\")[-1]\n",
    "    ax.set_title(new_title, fontdict={'weight': 'bold', 'size': font_size})\n",
    "    ax.set_ylabel(f\"Label\", fontdict={'weight': 'bold', 'size': font_size})\n",
    "    ax.set_xlabel(f\"Client ID\", fontdict={'weight': 'bold', 'size': font_size})\n",
    "    ax.set_xticks(list(set(df_combined['x'])), list(set(df_combined['x'])), size=font_size, weight='bold')\n",
    "    ax.set_yticks(list(set(df_combined['y'])), list(set(df_combined['y'])), size=font_size, weight='bold')\n",
    "\n",
    "plt.show()\n",
    "g.savefig('./dirichlet_partition.png', bbox_inches = \"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1217010e0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shards = [50, 100, 500, 1000][::-1]\n",
    "dataset_config = {\n",
    "    \"type\": \"CIFAR10\",\n",
    "    \"splitter_config\": {\n",
    "        \"type\": \"ShardSplitter\",\n",
    "        \"num_clients\": 15,\n",
    "        \"num_shards\": tune.grid_search(num_shards)\n",
    "    },\n",
    "}\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    partition_dataset,\n",
    "    param_space=dataset_config,\n",
    ")\n",
    "results = tuner.fit()\n",
    "\n",
    "dfs = []\n",
    "for result in results:\n",
    "    params_path = os.path.join(result.path, \"params.pkl\")\n",
    "    result_path = os.path.join(result.path, \"result.json\")\n",
    "    # 读取 .pkl 文件\n",
    "    with open(params_path, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    \n",
    "    with open(result_path, 'r') as file:\n",
    "        exp_result = json.load(file)\n",
    "\n",
    "    # 创建 DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'x': exp_result['result'][0],\n",
    "        'y': exp_result['result'][1],\n",
    "        'sizes': exp_result['result'][2],\n",
    "        'num_shards': [params['splitter_config']['num_shards']]* len(exp_result['result'][0])\n",
    "    })\n",
    "    dfs.append(df)\n",
    "df_combined = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a876a445a9bdd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建 FacetGrid 对象\n",
    "g = sns.FacetGrid(df_combined, col=\"num_shards\", col_wrap=4, col_order=num_shards, height=4., sharey=True, sharex=False)\n",
    "\n",
    "# 在每个子网格中添加散点图\n",
    "g.map_dataframe(sns.scatterplot, 'x', 'y', size='sizes', hue='x', sizes=(0, 500), palette=\"muted\",\n",
    "    edgecolor=\"black\", linewidth=1, \n",
    "    legend=False,)\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for _, spine in ax.spines.items():\n",
    "        spine.set_visible(True)\n",
    "    new_title = ax.get_title().split(\"=\")[-1] + \" shards\"\n",
    "    ax.set_title(new_title, fontdict={'weight': 'bold', 'size': font_size})\n",
    "    ax.set_ylabel(f\"Label\", fontdict={'weight': 'bold', 'size': font_size})\n",
    "    ax.set_xlabel(f\"Client ID\", fontdict={'weight': 'bold', 'size': font_size})\n",
    "    ax.set_xticks(list(set(df_combined['x'])), list(set(df_combined['x'])), size=font_size, weight='bold')\n",
    "    ax.set_yticks(list(set(df_combined['y'])), list(set(df_combined['y'])), size=font_size, weight='bold')\n",
    "\n",
    "plt.show()\n",
    "g.savefig('./shard_partition', bbox_inches = \"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbfc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
